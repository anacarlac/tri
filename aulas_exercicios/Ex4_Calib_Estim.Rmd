---
title: Exercício 4. Extimação de habilidades
author: "Ricardo Primi"
date: "26 de abril de 2021"
output: 
  html_document: 
    highlight: textmate
    theme: paper
---

```{r global_options, include=FALSE}
  knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

```{r}

library(tidyverse)

```

#### Exemplo de JMLE da aula de Linacre 

Ver link: https://www.youtube.com/watch?v=LvE8npeSjZ0&t=680s  

* Helper functions
```{r}
  
  f <- function(th, b){
    p_th = exp(th - b) / ( 1 + exp(th - b))
    p_th
  }
  
  
  df <- tibble(
    theta = seq(-3, 3, by=.01),
  )
  
  df$p <- f(th = df$theta, b = 0)
  
  ggplot(df, aes(y = p, x=theta)) + geom_line(color = "red")

```
## Estimação das habilidades quando conhecemos a habilidade

#### Método de Newton-Raphson NR 
```{r}
  
  mary <- c(1,1,1,0,0)
  george <- c(0,1,1,0,1)
  
  bs <- c(1, 2, 3, 4, 5)
  
  obs <- sum(mary)
  
```

* Testando valores de theta 1

```{r}
 
  th0 = 3
  pred <- f(th = th0, b = bs)
  round(pred, 2)
  esp0 <- sum(pred)
  obs-esp0

```

* Testando valores de theta 2

```{r}

  th1 = 4
  pred <- f(th = th1, b = bs)
  round(pred, 2)
  esp1 <- sum(pred)
  obs-esp1
  
```

* Atualizando theta pela formula de Newton-Raphson

* Iteração 0

```{r}

  th0 = 3
  pred <- f(th = th0, b = bs)
  esp0 <- sum(pred)
  
  um_menos_p <- 1-pred
  pred*um_menos_p
  
  pq q = 1-p
  
  pred
  1-pred
  
  var <- pred*(1-pred)
  
  esp0 <- sum(pred)
  
  th1 <- th0 + ((obs - esp0)/sum(var))

```

* Iteração 1  
```{r}

  pred <- f(th = th1, b = bs)
  esp1 <- sum(pred)
  th2 <- th1 + ((obs - esp1)/sum(var))
  
```

* Iteração 2  
```{r}

  pred <- f(th = th2, b = bs)
  esp2<- sum(pred)
  th3 <- th2 + ((obs - esp2)/sum(var))

  (esp2 - obs) 
  
  round((esp2 - obs), 2)
  
```

#### Metodo de Máxima Verosimilhança - Maximum Likelihood (ML)

* Calculo da verossimilhança 
```{r}
  
   pred <- f(th = th3, b = bs)
   mary
   round(pred, 2)
   round(1 - pred, 2)


  (pred**mary)
  ((1-pred)**(1-mary))
   
   pred
   mary
   (pred**mary)
   (1-pred)**(1-mary)
   
   (pred**mary) * ((1-pred)**(1-mary))
  
  prod( (pred**mary) * ((1-pred)**(1-mary)) )
  
  
  
```

```{r}

verossim <- function(theta, vetor_resp, bs){
  
   pred <- f(th = theta, b = bs)
   p_vetor = prod((pred**vetor_resp) * ((1-pred)**(1-vetor_resp)))
  
   return(p_vetor)
}
  
  verossim(theta=1, vetor_resp=mary, bs=bs)
  verossim(theta=2, vetor_resp=mary, bs=bs)
  verossim(theta=3, vetor_resp=mary, bs=bs)
  verossim(theta=4, vetor_resp=mary, bs=bs)
  verossim(theta=5, vetor_resp=mary, bs=bs)
  
  
  verossim(theta=1, vetor_resp=george, bs=bs)
  verossim(theta=2, vetor_resp=george, bs=bs)
  verossim(theta=3, vetor_resp=george, bs=bs)
  verossim(theta=4, vetor_resp=george, bs=bs)
  verossim(theta=5, vetor_resp=george, bs=bs)

 
  df <- tibble(
    theta = seq(1, 5, by=.1),
  )


df$mary_veross  <- apply(
  df, 
  MARGIN = 1, 
  function(x){verossim(theta=x["theta"], vetor_resp=mary, bs=bs)}
  )


df$george_veross  <- apply(
  df, 
  MARGIN = 1, function(x){verossim(theta=x["theta"], vetor_resp=george,bs=bs)}
  )


 ggplot(df, aes(y = mary_veross, x=theta)) + geom_line(color = "blue")
 ggplot(df, aes(y = george_veross, x=theta)) + geom_line(color = "red")
 
 
 
 

```

* A função de maxima verossimilhança! ML
* Derivadas: https://www.desmos.com/calculator/p6zuigdaqf


```{r}

df %>% 
  pivot_longer(cols = 2:3, names_to = "pessoa", values_to = "veross") %>%
  ggplot(aes(y = veross, x=theta, color = pessoa)) + geom_line()

```

### Outfit (outlier-sensitive fit)
https://www.rasch.org/rmt/rmt162f.htm

* Resíduos padronizados

* X^2 = (obs - exp)^2 / sd^2 
* X^2 = (obs - exp)^2 / var 

* O que ocorre se o dado observado é igual ao predito ?
* outfit = sum(X^2)

```{r}
  
  pred <- f(th = th3, b = bs)
  
  mary
  pred
  variance <- pred*(1-pred)
  variance
  
  outfit_mary =  sum( (mary - pred)**2 / variance ) / length(mary)
  
  george
  pred
  (george - pred)
  
  outfit_george =  sum( (george - pred)**2 / variance ) / length(george) 
  
  sum( (george - pred)**2 / variance )
  (george - pred)**2 / variance
  
 # igual ao vídeo
  sum(round( (george - pred)**2, 2) / round(variance, 2)) 
 
 
```

### Infit (inlier-sensitive or information-weighted fit)

infit = sum( (obs - exp)^2 ) / sum(var)

```{r}

 infit_mary =  ( sum( (mary - pred)**2 ) / sum(variance ) ) 
 infit_george = ( sum( (george - pred)**2 ) / sum(variance ) ) 

```

* 0 - 1 - (1.3 a 1.4) 1.5  - 2 

### Expected a posteriori (EAP)

```{r}



```

